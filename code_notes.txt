Here are some tensor sizes put together :
The following numbers imply : Batch size = 1 , Number of sentences = 65 , Words on sentences in total : 1767 , Words on the question : 17
context_idxs : torch.Size([1, 1767])
ques_idxs : torch.Size([1, 17])
context_char_idxs : torch.Size([1, 1767, 16])
ques_char_idxs : torch.Size([1, 17, 16])
context_lens : tensor([1767])
y1 : torch.Size([1])
y2 : torch.Size([1])
q_type : torch.Size([1])
is_support : torch.Size([1, 65])
start_mapping : torch.Size([1, 1767, 65])
end_mapping : torch.Size([1, 1767, 65])
all_mapping : torch.Size([1, 1767, 65])


Inside forward:
sp_output : torch.Size([1, 1767, 160])
start_output : torch.Size([1, 65, 80])
end_output : torch.Size([1, 65, 80])
sp_output[:,:,self.hidden:] : torch.Size([1, 1767, 80])
sp_output concatenated (start_mapping , end_mapping): torch.Size([1, 65, 160])
sp_output_aux : torch.Size([1, 65, 1])
sp_output_t : torch.Size([1, 65, 1])
predict_support : torch.Size([1, 65, 2])


predicted:
logit1 : torch.Size([1, 1767])
logit2 : torch.Size([1, 1767])
predict_type : torch.Size([1, 3])
predict_support : torch.Size([1, 65, 2])

These 3 numbers change from on batch to another :
Number of sentences = 65 , Words on sentences in total : 1767 , Words on the question : 17
The mapping variables (start_mapping, end_mapping) are one-hot vectors, that simply yell where every sentence begin and where every sentence ends
The all_mapping variable, just has 1 from the start to the end of some sentence, indicating with 1 all words that belong to that sentence
